# Declare and Compose Context: A New Paradigm for MCP-native Software Engineering

> We propose a secure, web-based MCP admin that centralizes **Context Management** for AI applications across teams and organizations with integrated observability and cost control.

## Introduction

The advent of Large Language Models (LLMs) has fundamentally changed how we interact with software. Instead of searching on Google, people now converse with AI assistants. This evolution took another leap when LLMs gained the ability to execute software directly through "tools"—functions that take inputs and return outputs.

Initially, these tools ran in the same runtime environment as the LLM. However, the introduction of the Model Context Protocol (MCP) changed this paradigm. MCP provides a standardized way for AI systems to discover and invoke tools across process boundaries, enabling any service to expose its capabilities to AI agents in a consistent manner.

### The Problem

This new paradigm introduces significant challenges for teams and organizations:

**Connection Management**: Users must manage connections to numerous MCP services, each with its own authentication, payment, and configuration requirements.

**Access Control & Privacy**: There's no way to share MCP access within a team without sharing personal credentials. For example, if your team needs to send emails via an MCP tool, someone must connect their personal Gmail account for everyone to use—creating security risks and privacy concerns.

**Tool Orchestration**: MCP services operate in isolation, with no standard way to compose tools from multiple services or manage dependencies between them.

### Our Solution: MCP Mesh

We're building the first open-source MCP Mesh — a unified platform that solves these challenges by:

1. **Centralizing MCP connections**: Connect all your MCP services in one place with unified authentication

2. **Fine-grained access control**: Create teams and members with precise permissions:
   - Grant specific users access to specific MCP services
   - Share a single connection across your team without exposing credentials
   - Audit who accessed which tools and when
   - Revoke access instantly without changing passwords

3. **Enabling tool composition**: Allow MCP services to depend on each other, eliminating redundant account connections

4. **Providing zero-config deployment**: Run the MCP Mesh locally without complex setup

5. **Being MCP-native**: The Mesh itself exposes an MCP interface, allowing it to be used by any MCP-compatible client

### Apps: Extending MCP

In MCP Mesh, we use "App" and "MCP service" interchangeably. Apps are a superset of MCP — we extend the protocol to support additional features such as:

- **Native multi-tenancy**: Apps can expose configuration schemas via tool calls, which the Mesh renders as user-friendly forms
- **Tool dependencies**: Apps can declare dependencies on other apps' tools
- **Unified discovery**: Browse and install apps from a centralized marketplace
- **Team-based ACLs**: Built-in support for team hierarchies, roles, and fine-grained permissions

The result is a composable, secure, open-source infrastructure layer for the AI-native software era.

---

## Key Architectural Decisions

1. **Multi-Level Namespacing**: Operations can be scoped at workspace or project level:
   - **Workspace-scoped**: MCPs shared across all projects (when `projectId` is null)
   - **Project-scoped**: MCPs isolated to a single project (when `projectId` is set)
   - The database connection itself represents the organization/workspace boundary
   - Projects provide isolation for policies, teams, and audit logs

2. **MCP-Native API**: Instead of REST, the Mesh uses MCP tools for all management operations. This makes the Mesh itself an MCP service that can be accessed programmatically or via AI agents.

3. **Minimal Configuration**: Only one environment variable (`DATABASE_URL`). All authentication configuration is file-based (`auth-config.json`).

4. **JWT with Audience Claims**: Tokens include an `aud` claim with stable identifiers, enabling strong isolation and preventing cross-scope token reuse.

5. **Policy-Based Access Control**: Fine-grained permissions via Statements → Policies → Roles hierarchy, inspired by AWS IAM.

6. **Zero-Config SQLite**: Uses Bun's native SQLite by default. No database setup required. Upgrade to PostgreSQL when needed.

7. **Credential Isolation**: Original service tokens never leave the Mesh. The proxy replaces Mesh tokens with actual credentials at request time.

8. **Hierarchical URL Structure** (inspired by Kubernetes resource scoping):
   - `/mcp` - Workspace management (cluster-scoped operations)
   - `/mcp/:connection` - MCP proxy to workspace-scoped services (available to all projects)
   - `/:project/mcp` - Project-scoped operations (namespace-scoped)
   - `/:project/mcp/:connection` - MCP proxy to project-scoped services

---

## Implementation Architecture

### Code Organization

The codebase is organized to maintain clear separation of concerns between the HTTP API layer and the business logic (tools).

```
apps/mesh/
├── src/
│   ├── api/
│   │   ├── index.ts                 # Hono app initialization
│   │   ├── middlewares/
│   │   │   ├── inject-context.ts    # Middleware that injects MeshContext into requests
│   │   │   ├── auth.ts              # Authentication middleware
│   │   │   ├── project-scope.ts     # Project validation middleware
│   │   │   └── authorization.ts     # Authorization verification middleware
│   │   └── routes/
│   │       ├── root-mcp.ts          # /mcp routes (project management)
│   │       ├── project-mcp.ts       # /:project/mcp routes
│   │       └── proxy.ts             # /:project/mcp/:connection routes
│   │
│   ├── tools/
│   │   ├── project/
│   │   │   ├── create.ts            # PROJECT_CREATE
│   │   │   ├── list.ts              # PROJECT_LIST
│   │   │   ├── get.ts               # PROJECT_GET
│   │   │   ├── update.ts            # PROJECT_UPDATE
│   │   │   └── delete.ts            # PROJECT_DELETE
│   │   ├── connection/
│   │   │   ├── create.ts            # CONNECTION_CREATE
│   │   │   ├── list.ts              # CONNECTION_LIST
│   │   │   └── ...
│   │   ├── policy/
│   │   ├── role/
│   │   ├── token/
│   │   └── audit/
│   │
│   ├── core/
│   │   ├── mesh-context.ts          # MeshContext interface definition
│   │   ├── context-factory.ts       # Factory function to create MeshContext
│   │   ├── access-control.ts        # Access control helper for authorization
│   │   ├── define-tool.ts           # defineTool function for declarative tool definitions
│   │   ├── bindings.ts              # MCP binding definitions (CHAT, EMAIL, STORAGE, etc.)
│   │   └── binding-detector.ts      # Automatic binding detection for connections
│   │
│   ├── storage/
│   │   ├── schema.ts                # Drizzle schema definitions
│   │   ├── connection.ts            # ConnectionStorage (uses Drizzle)
│   │   ├── policy.ts                # PolicyStorage (uses Drizzle)
│   │   ├── project.ts               # ProjectStorage (uses Drizzle)
│   │   ├── role.ts                  # RoleStorage (uses Drizzle)
│   │   ├── token.ts                 # AccessTokenStorage (uses Drizzle)
│   │   ├── token-revocation.ts      # TokenRevocationStorage (uses Drizzle)
│   │   ├── team.ts                  # TeamStorage (uses Drizzle)
│   │   └── audit-log.ts             # AuditLogStorage (uses Drizzle)
│   │
│   ├── auth/
│   │   └── index.ts                 # Better Auth configuration with JWT + Admin plugins
│   │
│   └── encryption/
│       └── credential-vault.ts      # Credential encryption/decryption
```

### Architecture Principles

#### 1. Separation of Concerns

**API Layer Responsibilities:**

- HTTP request/response handling
- Middleware orchestration
- Context creation and injection
- Error handling and formatting
- Route definitions

**Tool Layer Responsibilities:**

- Business logic execution
- Data validation
- Authorization checks
- Storage operations via context interfaces

**Tools must NOT:**

- Access HTTP request/response objects directly
- Know about Hono or any HTTP framework details
- Import database drivers directly
- Handle HTTP status codes

#### 2. MeshContext: The Core Abstraction

Every tool receives a `MeshContext` that provides access to all necessary services through well-defined interfaces:

```typescript
// core/mesh-context.ts
interface MeshContext {
  // Authentication
  auth: {
    user?: User;
    session?: Session;
    token?: ParsedToken;
  };
  
  // Project scope (for namespace-scoped endpoints)
  // If undefined, context is workspace-scoped (cluster-level)
  project?: {
    id: string;
    slug: string;
    ownerId: string;
  };
  
  // Storage interfaces (database = workspace boundary)
  storage: {
    projects: ProjectStorage;
    connections: ConnectionStorage;
    policies: PolicyStorage;
    roles: RoleStorage;
    tokens: AccessTokenStorage;
    tokenRevocations: TokenRevocationStorage;
    teams: TeamStorage;
    auditLogs: AuditLogStorage;
  };
  
  // Security services
  jwt: JWTIssuer;
  vault: CredentialVault;
  
  // Access control (for authorization)
  access: AccessControl;
  
  // Current tool being executed (set by defineTool wrapper)
  toolName?: string;
  
  // Request metadata (non-HTTP specific)
  metadata: {
    requestId: string;
    timestamp: Date;
    userAgent?: string;
    ipAddress?: string;
  };
}
```

#### 3. Tool Definition Pattern

Tools are defined using the `defineTool` function with Zod schemas for type-safe validation:

```typescript
// core/define-tool.ts
import { z } from 'zod';
import type { MeshContext } from './mesh-context';

export interface ToolDefinition<TInput extends z.ZodType, TOutput extends z.ZodType> {
  name: string;
  description: string;
  inputSchema: TInput;
  outputSchema?: TOutput;
  handler: (input: z.infer<TInput>, ctx: MeshContext) => Promise<z.infer<TOutput>>;
}

export function defineTool<TInput extends z.ZodType, TOutput extends z.ZodType>(
  definition: ToolDefinition<TInput, TOutput>
) {
  return {
    ...definition,
    
    // Wrapped handler that adds context, authorization, validation, and logging
    execute: async (rawInput: unknown, ctx: MeshContext): Promise<z.infer<TOutput>> => {
      // Set tool name in context
      ctx.toolName = definition.name;
      
      // Validate input with Zod
      const input = definition.inputSchema.parse(rawInput);
      
      // Execute handler
      const output = await definition.handler(input, ctx);
      
      // Validate output if schema provided
      const validatedOutput = definition.outputSchema 
        ? definition.outputSchema.parse(output)
        : output;
      
      // Automatic audit logging
      await ctx.storage.auditLogs.log({
        projectId: ctx.project?.id,
        userId: ctx.auth.user?.id,
        toolName: definition.name,
        allowed: ctx.access.granted(),
        timestamp: new Date(),
        requestMetadata: { input },
      });
      
      return validatedOutput;
    },
  };
}
```

**Example Tool Definition:**

```typescript
// tools/connection/create.ts
import { z } from 'zod';
import { defineTool } from '../../core/define-tool';

const connectionSchema = z.discriminatedUnion('type', [
  z.object({
    type: z.literal('HTTP'),
    url: z.string().url(),
    token: z.string().optional(),
  }),
  z.object({
    type: z.literal('SSE'),
    url: z.string().url(),
    token: z.string().optional(),
    headers: z.record(z.string()).optional(),
  }),
  z.object({
    type: z.literal('Websocket'),
    url: z.string().url(),
    token: z.string().optional(),
  }),
]);

export const CONNECTION_CREATE = defineTool({
  name: 'CONNECTION_CREATE',
  description: 'Create a new MCP connection in the project',
  
  // Zod schema for type-safe validation
  inputSchema: z.object({
    name: z.string().min(1).max(255),
    description: z.string().optional(),
    icon: z.string().optional(),
    projectId: z.string().nullable().optional(), // null = workspace-scoped
    connection: connectionSchema,
    metadata: z.record(z.any()).optional(),
  }),
  
  outputSchema: z.object({
    id: z.string(),
    name: z.string(),
    scope: z.enum(['workspace', 'project']),
    status: z.enum(['active', 'inactive', 'error']),
  }),
  
  handler: async (input, ctx) => {
    // Check authorization (checks current tool name by default)
    await ctx.access.check();
    
    // Business logic
    const connection = await ctx.storage.connections.create({
      projectId: ctx.project?.id ?? null, // null = workspace-scoped
      ...input,
      createdById: ctx.auth.user!.id,
    });
    
    return {
      id: connection.id,
      name: connection.name,
      scope: connection.projectId ? 'project' : 'workspace',
      status: connection.status,
    };
  },
});
```

**Benefits of `defineTool`:**

1. **Type-Safe**: Zod schemas provide compile-time and runtime type safety
2. **Automatic Validation**: Input and output are validated automatically
3. **Declarative**: Schema and handler are co-located
4. **Automatic Logging**: Audit logs are automatically created
5. **Self-Documenting**: Zod schemas serve as documentation and can generate JSON Schema for MCP
6. **Testable**: Easy to mock and test handlers
7. **MCP Compatible**: Tool definitions can be exposed directly via MCP protocol

#### 4. Authorization Pattern

Tools must explicitly authorize operations using the improved access control API. The authorization flow follows this pattern:

**Step 1: Middleware Injects Context**

```typescript
// api/middlewares/inject-context.ts
app.use('*', async (c, next) => {
  const ctx: MeshContext = await createMeshContext(c);
  c.set('meshContext', ctx);
  await next();
});
```

**Step 2: Tool Pipeline Checks Policies (Non-Blocking)**

```typescript
// api/middlewares/authorization.ts
app.use('/mcp/tools/*', async (c, next) => {
  const ctx = c.get('meshContext');
  const toolName = extractToolName(c.req.path);
  
  // Check if user has policies that MIGHT allow this tool
  // This is a pre-check, not enforcement
  const hasRelevantPolicies = await ctx.storage.policies.userHasPolicies(
    ctx.auth.user?.id,
    ctx.project?.id
  );
  
  if (!hasRelevantPolicies) {
    throw new ForbiddenError('No policies found for user');
  }
  
  // Continue - tool will do fine-grained check
  await next();
});
```

**Step 3: Tool Explicitly Grants Access**

```typescript
// tools/connection/create.ts
import { defineTool } from '../../core/define-tool';

export const CONNECTION_CREATE = defineTool({
  name: 'CONNECTION_CREATE',
  description: 'Create a new MCP connection in the project',
  
  // JSON Schema (validated by MCP protocol layer)
  inputSchema: {
    type: 'object',
    properties: {
      name: { type: 'string' },
      description: { type: 'string' },
      icon: { type: 'string' },
      connection: {
        type: 'object',
        oneOf: [
          {
            type: 'object',
            properties: {
              type: { type: 'string', const: 'HTTP' },
              url: { type: 'string', format: 'uri' },
              token: { type: 'string' },
            },
            required: ['type', 'url'],
          },
          {
            type: 'object',
            properties: {
              type: { type: 'string', const: 'SSE' },
              url: { type: 'string', format: 'uri' },
              token: { type: 'string' },
            },
            required: ['type', 'url'],
          },
          {
            type: 'object',
            properties: {
              type: { type: 'string', const: 'Websocket' },
              url: { type: 'string', format: 'uri' },
              token: { type: 'string' },
            },
            required: ['type', 'url'],
          },
        ],
      },
      metadata: { type: 'object' },
    },
    required: ['name', 'connection'],
  },
  
  handler: async (input, ctx) => {
    // Input is already validated by MCP protocol layer
    
    // Check authorization and grant access if allowed
    // ctx.toolName is automatically set to 'CONNECTION_CREATE'
    await ctx.access.grant(); // Grant access to current tool
    
    // Perform the actual work
    const connection = await ctx.storage.connections.create({
    projectId: ctx.project!.id,
      ...input,
    });
    
    // Log the action (automatically logged by defineTool wrapper)
    // No need to manually log - the framework does it
    
    return {
      id: connection.id,
      name: connection.name,
      status: connection.status,
      createdAt: connection.createdAt,
    };
  },
});
```

**Access Control API:**

The `ctx.access` object provides a clean API for authorization checks using Better Auth's permission model:

```typescript
// core/access-control.ts
import type { Permission } from '../storage/schema';

export class AccessControl {
  private _granted: boolean = false;
  
  constructor(
    private toolName?: string,
    private permissions?: Permission,
    private role?: string,
    private connectionId?: string
  ) {}
  
  /**
   * Grant access without checking (use after manual validation)
   * Just sets the granted flag to true
   */
  grant(): Disposable {
    this._granted = true;
    return {
      [Symbol.dispose]() {
        // Cleanup if needed
      }
    };
  }
  
  /**
   * Check permissions and grant access if allowed
   * Inspired by assertWorkspaceResourceAccess from assertions.ts
   * 
   * @param resources - Optional connection IDs or tool names to check
   * If omitted, checks the current tool name against all connections
   */
  async check(...resources: string[]): Promise<Disposable> {
    // If already granted, return immediately
    if (this._granted) {
      return this.grant();
    }
    
    // Admin role bypasses all checks
    if (this.role === 'admin') {
      return this.grant();
    }
    
    // Determine what to check
    const resourcesToCheck = resources.length > 0 
      ? resources 
      : this.toolName ? [this.toolName] : [];
    
    if (resourcesToCheck.length === 0) {
      throw new ForbiddenError('No resources specified for access check');
    }
    
    // If no permissions, deny access
    if (!this.permissions || Object.keys(this.permissions).length === 0) {
      throw new ForbiddenError('No permissions granted to user');
    }
    
    // Check each resource - if ANY succeeds, grant access (OR logic)
    for (const resource of resourcesToCheck) {
      // Check if permission grants access to this tool via any connection
      for (const [connId, tools] of Object.entries(this.permissions)) {
        // If checking a specific connection, skip others
        if (this.connectionId && connId !== this.connectionId) {
          continue;
        }
        
        // Check if tool is in the allowed list for this connection
        if (tools.includes(resource) || tools.includes('*')) {
          return this.grant();
        }
      }
    }
    
    // No permission found for any of the requested resources
    throw new ForbiddenError(
      `Access denied to: ${resourcesToCheck.join(', ')}`
    );
  }
  
  /**
   * Check if access was granted
   */
  granted(): boolean {
    return this._granted;
  }
}
```

**Usage Examples:**

```typescript
// Example 1: Grant access to current tool
export const CREATE_CONNECTION = defineTool({
  name: 'CREATE_CONNECTION',
  handler: async (input, ctx) => {
    // Check if user has permission and grant access
    await ctx.access.grant(); // Checks current tool (CREATE_CONNECTION)
    
    // Business logic...
  },
});

// Example 2: Check access to specific tool before delegating
export const BULK_CREATE_CONNECTIONS = defineTool({
  name: 'BULK_CREATE_CONNECTIONS',
  handler: async (input, ctx) => {
    // First grant access to this tool
    await ctx.access.grant();
    
    // Check if user has CREATE_CONNECTION permission before delegating
    await ctx.access.grant('CREATE_CONNECTION');
    
    // Now we can call CREATE_CONNECTION for each item...
  },
});

// Example 3: Check multiple tools (OR logic)
export const SYNC_DATA = defineTool({
  name: 'SYNC_DATA',
  handler: async (input, ctx) => {
    await ctx.access.grant();
    
    // User needs access to at least ONE of these tools
    // Throws if user has none of them
    await ctx.access.grant('READ_FROM_SOURCE', 'READ_FROM_CACHE');
    
    // Business logic...
  },
});

// Example 4: Conditional access check
export const PROCESS_DOCUMENT = defineTool({
  name: 'PROCESS_DOCUMENT',
  handler: async (input, ctx) => {
    await ctx.access.grant();
    
    if (input.useAI) {
      // Only check AI_PROCESS if needed
      await ctx.access.grant('AI_PROCESS');
    }
    
    // Business logic...
  },
});
```

**Step 4: Final Middleware Verifies Grant**

```typescript
// api/middlewares/authorization.ts
app.use('*', async (c, next) => {
  await next();
  
  // After tool execution, verify authorization was handled
  const ctx = c.get('meshContext');
  
  if (!ctx.access.granted()) {
    // Tool forgot to call grant() - if not granted, access is denied
    throw new Error('SECURITY: Tool did not grant access');
  }
});
```

#### 4. Storage Port & Adapter Pattern

Storage ports define the contracts, and adapters implement them for specific databases:

```typescript
// storage/ports.ts
export interface ConnectionStorage {
  create(data: CreateConnectionData): Promise<MCPConnection>;
  findById(id: string): Promise<MCPConnection | null>;
  findByProjectId(projectId: string): Promise<MCPConnection[]>;
  update(id: string, data: Partial<MCPConnection>): Promise<MCPConnection>;
  delete(id: string): Promise<void>;
  
  // Connection-specific queries
  findByTeamId(teamId: string): Promise<MCPConnection[]>;
  testConnection(id: string): Promise<ConnectionTestResult>;
}

// storage/connection.ts
import type { BunSQLiteDatabase } from 'drizzle-orm/bun-sqlite';
import { eq, and } from 'drizzle-orm';
import * as schema from './schema';

export class ConnectionStorage implements ConnectionStoragePort {
  constructor(private drizzle: BunSQLiteDatabase<typeof schema>) {}
  
  async create(data: CreateConnectionData): Promise<MCPConnection> {
    const [connection] = await this.drizzle
      .insert(schema.connections)
      .values({
        id: crypto.randomUUID(),
        projectId: data.projectId,
        name: data.name,
        connectionType: data.connection.type,
        connectionUrl: data.connection.url,
        // ... other fields
      })
      .returning();
    
    return connection;
  }
  
  async findById(id: string): Promise<MCPConnection | null> {
    const [connection] = await this.drizzle
      .select()
      .from(schema.connections)
      .where(eq(schema.connections.id, id))
      .limit(1);
    
    return connection || null;
  }
  
  async list(projectId: string | null): Promise<MCPConnection[]> {
    // If projectId is null, return workspace-scoped connections
    // Otherwise return both workspace + project connections
    const query = projectId
      ? and(
          eq(schema.connections.projectId, projectId),
          // OR workspace-scoped (projectId is null)
        )
      : eq(schema.connections.projectId, null);
    
    return await this.drizzle
      .select()
      .from(schema.connections)
      .where(query);
  }
  
  // ... other methods
}
```

#### 5. JWT Authentication via Better Auth

The Mesh uses [Better Auth's JWT plugin](https://www.better-auth.com/docs/plugins/jwt) for token issuance and verification, providing standard JWKS support:

**Configuration:**

```typescript
// auth/index.ts
import { betterAuth } from "better-auth";
import { jwt } from "better-auth/plugins";
import { admin } from "better-auth/plugins";

export const auth = betterAuth({
  database: {
    provider: "sqlite",
    db: sqlite, // Bun SQLite instance
  },
  plugins: [
    // JWT plugin for MCP client authentication
    jwt({
      jwks: {
        keyPairConfig: {
          alg: 'EdDSA', // EdDSA with Ed25519 (fastest, most secure)
          crv: 'Ed25519',
        },
      },
      jwt: {
        issuer: process.env.BASE_URL || "http://localhost:3000",
        audience: process.env.BASE_URL || "http://localhost:3000",
        expirationTime: "1h",
        
        // Custom JWT payload with MCP Mesh claims
        definePayload: ({ user, session }) => {
          return {
            userId: user.id,
            role: user.role,
            permissions: user.permissions, // Better Auth permissions
            projectId: session.projectId,
            projectSlug: session.projectSlug,
          };
        },
      },
    }),
    
    // Admin plugin for role-based access
    admin({
      defaultRole: "user",
      adminRoles: ["admin"],
    }),
  ],
});
```

**Token Issuance:**

MCP clients get JWT tokens via the `/api/auth/token` endpoint:

```typescript
// Client gets token after Better Auth session
const response = await fetch('/api/auth/token', {
  headers: {
    'Authorization': `Bearer ${sessionToken}`,
  },
});

const { token } = await response.json();
// Use this JWT token for MCP operations
```

**Token Verification:**

MCP clients can verify tokens using the public JWKS endpoint without calling back to the Mesh:

```typescript
// MCP Client (TypeScript example)
import { jwtVerify, createRemoteJWKSet } from 'jose';

async function validateMeshToken(token: string) {
  const JWKS = createRemoteJWKSet(
    new URL('https://mesh.example.com/api/auth/jwks')
  );
  
  const { payload } = await jwtVerify(token, JWKS, {
    issuer: 'https://mesh.example.com',
    audience: 'https://mesh.example.com',
  });
  
  return payload as {
    userId: string;
    role: string;
    permissions: Record<string, string[]>; // { connectionId: ["tool1", "tool2"] }
    projectId?: string;
    projectSlug?: string;
  };
}
```

**Better Auth JWT Benefits:**

1. **Standard JWKS Endpoint**: `/api/auth/jwks` provides public keys for token verification
2. **Automatic Key Rotation**: Better Auth handles key rotation seamlessly with `kid` in JWT headers
3. **Stateless Verification**: MCP clients verify tokens locally without database calls
4. **EdDSA/Ed25519**: Fastest signature algorithm with smallest key size
5. **OAuth2/OIDC Compatible**: Enterprise-ready for SSO integration
6. **Custom Claims**: Embed permissions directly in JWT payload
7. **Issuer/Audience Validation**: Built-in protection against token misuse
8. **No Maintenance**: Battle-tested JWT implementation, no custom code needed

**Token Revocation** (Optional):

While Better Auth JWT tokens are stateless, you can implement revocation for security-critical operations:

```typescript
// Check if token is revoked before granting access
const isRevoked = await tokenRevocationStorage.isRevoked(payload.jti);
if (isRevoked) {
  throw new UnauthorizedError('Token has been revoked');
}
```

#### 6. MCP Bindings: Protocol-Level Interfaces

MCP Bindings are a powerful abstraction that enables polymorphic tool implementations across different providers. Think of bindings as TypeScript interfaces, but for MCP tools—they define a contract that any MCP service can implement.

**Concept:**

A binding is a named set of tool signatures. If an MCP connection implements all the tools in a binding, it conforms to that binding type. This follows the "duck typing" principle: if it implements the right tools, it's the right type.

**Why Bindings Matter:**

1. **Provider Interchangeability**: Switch between Gmail, Outlook, or SendGrid without changing your application code
2. **Generic UIs**: Build a chat interface once, plug in any CHAT-compatible MCP provider
3. **Dependency Management**: Tools can depend on bindings instead of specific connections
4. **Marketplace Discovery**: Filter MCP apps by the bindings they implement

**Example Bindings:**

```typescript
// core/bindings.ts
import { z } from 'zod';

// CHAT Binding: Conversational messaging interface
export const CHAT_BINDING = {
  name: 'CHAT',
  version: '1.0.0',
  tools: {
    SEND_MESSAGE: {
      description: 'Send a message to a conversation',
      inputSchema: z.object({
        threadId: z.string(),
        content: z.string(),
        attachments: z.array(z.string()).optional(),
      }),
    },
    LIST_THREADS: {
      description: 'List all conversation threads',
      inputSchema: z.object({
        limit: z.number().optional(),
        offset: z.number().optional(),
      }),
    },
    GET_THREAD: {
      description: 'Get details of a specific thread',
      inputSchema: z.object({
        threadId: z.string(),
      }),
    },
    LIST_MESSAGES: {
      description: 'List messages in a thread',
      inputSchema: z.object({
        threadId: z.string(),
        limit: z.number().optional(),
      }),
    },
  },
};

// EMAIL Binding: Email sending and management
export const EMAIL_BINDING = {
  name: 'EMAIL',
  version: '1.0.0',
  tools: {
    SEND_EMAIL: {
      description: 'Send an email',
      inputSchema: z.object({
        to: z.array(z.string().email()),
        subject: z.string(),
        body: z.string(),
        attachments: z.array(z.string()).optional(),
      }),
    },
    LIST_EMAILS: {
      description: 'List emails in inbox',
      inputSchema: z.object({
        folder: z.string().optional(),
        limit: z.number().optional(),
      }),
    },
    GET_EMAIL: {
      description: 'Get a specific email',
      inputSchema: z.object({
        emailId: z.string(),
      }),
    },
  },
};

// STORAGE Binding: File storage operations
export const STORAGE_BINDING = {
  name: 'STORAGE',
  version: '1.0.0',
  tools: {
    UPLOAD_FILE: {
      description: 'Upload a file',
      inputSchema: z.object({
        path: z.string(),
        content: z.string(),
        contentType: z.string().optional(),
      }),
    },
    DOWNLOAD_FILE: {
      description: 'Download a file',
      inputSchema: z.object({
        path: z.string(),
      }),
    },
    LIST_FILES: {
      description: 'List files in a directory',
      inputSchema: z.object({
        path: z.string().optional(),
      }),
    },
    DELETE_FILE: {
      description: 'Delete a file',
      inputSchema: z.object({
        path: z.string(),
      }),
    },
  },
};
```

**Binding Detection:**

The Mesh automatically detects which bindings a connection implements:

```typescript
// core/binding-detector.ts
export function detectBindings(
  connection: MCPConnection
): string[] {
  const bindings: string[] = [];
  const toolNames = connection.tools?.map(t => t.name) || [];
  
  // Check each registered binding
  for (const binding of REGISTERED_BINDINGS) {
    const requiredTools = Object.keys(binding.tools);
    const hasAllTools = requiredTools.every(tool => 
      toolNames.includes(tool)
    );
    
    if (hasAllTools) {
      bindings.push(binding.name);
    }
  }
  
  return bindings;
}
```

**Using Bindings in Policies:**

Bindings don't affect policies directly. Policies grant access to specific tool names. The value of bindings is for **discovery and UI generation**, not authorization:

```typescript
// Policy grants access to specific tools (not bindings)
{
  "name": "Chat Access",
  "statements": [
    {
      "effect": "allow",
      "resource": "SEND_MESSAGE",  // Grant access to this specific tool
      "actions": ["execute"]
    },
    {
      "effect": "allow",
      "resource": "LIST_THREADS",  // Grant access to this tool
      "actions": ["execute"]
    }
  ]
}

// The Mesh automatically detects that connections providing these tools
// implement the CHAT binding, which helps UIs discover compatible providers
```

**Building Generic UIs with Bindings:**

```typescript
// Generic chat component that works with any CHAT binding provider
export function ChatInterface({ projectSlug }: { projectSlug: string }) {
  const { data: connections } = useConnections(projectSlug);
  
  // Find any connection that implements CHAT binding
  const chatProvider = connections?.find(conn => 
    conn.bindings?.includes('CHAT')
  );
  
  if (!chatProvider) {
    return <div>No chat provider connected</div>;
  }
  
  // Use the provider's tools through the binding interface
  const sendMessage = async (threadId: string, content: string) => {
    await mcpProxy.call(chatProvider.id, 'SEND_MESSAGE', {
      threadId,
      content,
    });
  };
  
  return <ChatUI onSendMessage={sendMessage} />;
}
```

**Marketplace Integration:**

Apps in the marketplace can declare which bindings they implement:

```typescript
// App metadata
{
  "id": "slack-mcp",
  "name": "Slack",
  "description": "Slack integration via MCP",
  "implements": ["CHAT"],
  "tools": [
    "SEND_MESSAGE",
    "LIST_THREADS",
    "GET_THREAD",
    "LIST_MESSAGES"
  ]
}
```

Users can filter apps by binding:

```typescript
POST /my-project/mcp/tools/MARKETPLACE_SEARCH
{
  "binding": "CHAT"
}
// Returns: [{ name: "Slack" }, { name: "Discord" }, { name: "Teams" }]
```

**Benefits of Bindings:**

1. **Abstraction**: Code against interfaces, not implementations
2. **Flexibility**: Swap providers without code changes
3. **Reusability**: Generic UI components work with multiple providers
4. **Discoverability**: Find compatible apps in marketplace
5. **Type Safety**: Binding schemas provide validation
6. **Composability**: Tools can depend on bindings, not specific connections

#### 8. Context Factory

The context factory creates MeshContext with Drizzle ORM for database access:

```typescript
// core/context-factory.ts
import { drizzle } from 'drizzle-orm/bun-sqlite';
import type { BunSQLiteDatabase } from 'drizzle-orm/bun-sqlite';
import * as schema from '../storage/schema';

export interface MeshContextConfig {
  drizzle: BunSQLiteDatabase<typeof schema>; // Drizzle instance
  jwt: {
    issuer: JWTIssuer;
  };
  encryption: {
    key: string;
  };
}

export function createMeshContextFactory(
  config: MeshContextConfig
): (c: Context) => Promise<MeshContext> {
  // Create storage adapters using Drizzle
  const storage = {
    projects: new ProjectStorage(config.drizzle),
    connections: new ConnectionStorage(config.drizzle),
    policies: new PolicyStorage(config.drizzle),
    roles: new RoleStorage(config.drizzle),
    tokens: new AccessTokenStorage(config.drizzle),
    tokenRevocations: new TokenRevocationStorage(config.drizzle),
    teams: new TeamStorage(config.drizzle),
    auditLogs: new AuditLogStorage(config.drizzle),
  };
  
  const jwt = config.jwt.issuer;
  const vault = new CredentialVault(config.encryption.key);
  
  // Return factory function
  return async (c: Context): Promise<MeshContext> => {
    // Extract auth from request
    const authHeader = c.req.header('Authorization');
    const token = authHeader?.replace('Bearer ', '');
    
    let auth: MeshContext['auth'] = {};
    if (token) {
      // Comprehensive JWT validation
      const parsed = await jwt.verify(token, {
        issuer: config.jwt.issuer,              // Verify iss matches configured base URL
        clockTolerance: 60,                      // 60 second clock skew tolerance
        strictExp: true,                         // Strictly enforce expiration
      });
      
      // Check jti against revocation list
      const isRevoked = await storage.tokens.isRevoked(parsed.jti);
      if (isRevoked) {
        throw new UnauthorizedError('Token has been revoked');
      }
      
      // Verify nbf (not before) with clock tolerance
      const now = Math.floor(Date.now() / 1000);
      if (parsed.nbf && now < parsed.nbf - 60) {
        throw new UnauthorizedError('Token not yet valid');
      }
      
      auth = {
        user: parsed.userId ? await storage.users.findById(parsed.userId) : undefined,
        token: parsed,
      };
    }
    
    // Extract project from path (Kubernetes namespace concept)
    const projectSlug = extractProjectSlug(c.req.path);
    let project: MeshContext['project'] | undefined;
    if (projectSlug) {
      // Namespace-scoped (project-level) request
      project = await storage.projects.findBySlug(projectSlug);
      
      if (!project) {
        throw new NotFoundError('Project not found');
      }
      
      // Verify token audience matches stable project identifier
      // aud format: "project:<projectId>"
      const expectedAud = `project:${project.id}`;
      if (auth.token && auth.token.aud !== expectedAud) {
        throw new UnauthorizedError(
          `Token audience mismatch: expected ${expectedAud}, got ${auth.token.aud}`
        );
      }
      
      // Optional: Verify projectSlug claim matches for convenience
      if (auth.token && auth.token.projectSlug !== projectSlug) {
        throw new UnauthorizedError('Token project slug mismatch');
      }
    } else {
      // Cluster-scoped (workspace-level) request
      // Verify token audience is workspace-scoped
      if (auth.token && auth.token.aud !== 'workspace') {
        throw new UnauthorizedError(
          `Token audience mismatch: expected "workspace" for cluster-level operations, got ${auth.token.aud}`
        );
      }
    }
    
    return {
      auth,
      project,
      storage,
      jwt,
      vault,
      access: new AccessControl(),
      metadata: {
        requestId: crypto.randomUUID(),
        timestamp: new Date(),
        userAgent: c.req.header('User-Agent'),
        ipAddress: c.req.header('CF-Connecting-IP') || c.req.header('X-Forwarded-For'),
      },
    };
  };
}
```

#### 9. Tool Registration and Pipeline

```typescript
// api/index.ts
import { Hono } from 'hono';
import { createMeshContextFactory } from '../core/context-factory';
import * as ProjectTools from '../tools/project';
import * as ConnectionTools from '../tools/connection';

const app = new Hono();

// Load configuration
const config = loadConfig();

// Create context factory
const createContext = createMeshContextFactory(config);

// Register middleware
app.use('*', async (c, next) => {
  const ctx = await createContext(c);
  c.set('meshContext', ctx);
  await next();
});

// Tool execution handler
async function executeTool(
  c: Context,
  toolName: string,
  args: unknown
): Promise<unknown> {
  const ctx = c.get('meshContext') as MeshContext;
  
  // Find tool definition
  const tool = TOOL_REGISTRY.find(t => t.name === toolName);
  if (!tool) {
    throw new Error(`Unknown tool: ${toolName}`);
  }
  
  // Execute tool using defineTool's execute method
  // This handles: validation, authorization checking, logging
  const result = await tool.execute(args, ctx);
  
  // Verify authorization was checked (safety check)
  if (!ctx.access.granted()) {
    throw new Error(`SECURITY: Tool ${toolName} did not grant access`);
  }
  
  return result;
}

// Root-level MCP endpoints
app.post('/mcp/tools/:toolName', async (c) => {
  const toolName = c.req.param('toolName');
  const args = await c.req.json();
  
  const result = await executeTool(c, toolName, args);
  return c.json({ result });
});

// Project-scoped MCP endpoints
app.post('/:project/mcp/tools/:toolName', async (c) => {
  const toolName = c.req.param('toolName');
  const args = await c.req.json();
  
  const result = await executeTool(c, toolName, args);
  return c.json({ result });
});

// Tool registry - Array of all available tools
const TOOL_REGISTRY = [
  // Project Management
  ProjectTools.PROJECT_CREATE,
  ProjectTools.PROJECT_LIST,
  ProjectTools.PROJECT_GET,
  ProjectTools.PROJECT_UPDATE,
  ProjectTools.PROJECT_DELETE,
  
  // Connection Management
  ConnectionTools.CONNECTION_CREATE,
  ConnectionTools.CONNECTION_LIST,
  ConnectionTools.CONNECTION_GET,
  ConnectionTools.CONNECTION_UPDATE,
  ConnectionTools.CONNECTION_DELETE,
  ConnectionTools.CONNECTION_TEST,
  
  // Policy Management
  PolicyTools.POLICY_CREATE,
  PolicyTools.POLICY_LIST,
  PolicyTools.POLICY_UPDATE,
  PolicyTools.POLICY_DELETE,
  
  // Role Management
  RoleTools.ROLE_CREATE,
  RoleTools.ROLE_LIST,
  RoleTools.ROLE_UPDATE,
  RoleTools.ROLE_DELETE,
  
  // Token Management
  TokenTools.TOKEN_CREATE,
  TokenTools.TOKEN_LIST,
  TokenTools.TOKEN_REVOKE,
];
```

#### 10. Testing Strategy

The MeshContext abstraction and `defineTool` pattern enable comprehensive testing without HTTP servers:

```typescript
// tools/connection/create.test.ts
import { describe, it, expect } from 'bun:test';
import { CONNECTION_CREATE } from './create';
import { createMockContext } from '../../test-utils/mock-context';

describe('CONNECTION_CREATE', () => {
  it('creates connection when authorized', async () => {
    // Mock storage adapters
    const mockStorageAdapters = {
      connections: {
        create: async (data) => ({ 
          id: 'conn_123', 
          status: 'active',
          createdAt: new Date(),
          ...data 
        }),
      },
      policies: {
        evaluate: async () => true, // User is authorized
      },
      auditLogs: {
        log: async () => {},
      },
    };
    
    const ctx = createMockContext({
      auth: { user: { id: 'user_abc' } },
      project: { id: 'proj_xyz', slug: 'test' },
      storage: mockStorageAdapters,
    });
    
    // Call tool.execute() instead of calling handler directly
    const result = await CONNECTION_CREATE.execute({
      name: 'Test Connection',
      connection: { type: 'HTTP', url: 'https://example.com' },
    }, ctx);
    
    expect(result.id).toBe('conn_123');
    expect(result.name).toBe('Test Connection');
    expect(ctx.access.granted()).toBe(true);
  });
  
  it('throws when not authorized', async () => {
    const mockStorageAdapters = {
      policies: {
        evaluate: async () => false, // User is NOT authorized
      },
      auditLogs: {
        log: async () => {},
      },
    };
    
    const ctx = createMockContext({
      auth: { user: { id: 'user_abc' } },
      project: { id: 'proj_xyz', slug: 'test' },
      storage: mockStorageAdapters,
    });
    
    await expect(
      CONNECTION_CREATE.execute({ 
        name: 'Test', 
        connection: { type: 'HTTP', url: 'https://example.com' } 
      }, ctx)
    ).rejects.toThrow('Not allowed to execute CONNECTION_CREATE');
  });
  
  it('automatically logs audit trail', async () => {
    const auditLogSpy = vi.fn();
    const mockStorageAdapters = {
      connections: {
        create: async (data) => ({ 
          id: 'conn_123', 
          status: 'active',
          createdAt: new Date(),
          ...data 
        }),
      },
      policies: {
        evaluate: async () => true,
      },
      auditLogs: {
        log: auditLogSpy, // Spy on audit logging
      },
    };
    
    const ctx = createMockContext({
      auth: { user: { id: 'user_abc' } },
      project: { id: 'proj_xyz', slug: 'test' },
      storage: mockStorageAdapters,
    });
    
    await CONNECTION_CREATE.execute({ 
      name: 'Test',
      connection: { type: 'HTTP', url: 'https://example.com' } 
    }, ctx);
    
    // Verify audit log was created automatically
    expect(auditLogSpy).toHaveBeenCalledWith(
      expect.objectContaining({
        toolName: 'CONNECTION_CREATE',
        allowed: true,
        userId: 'user_abc',
        projectId: 'proj_xyz',
      })
    );
  });
});
```

### Benefits of This Architecture

1. **MCP Native**: Uses JSON Schema for tool definitions, aligning with MCP protocol standards
2. **Declarative Tool Definition**: `defineTool` provides self-documenting tool definitions with automatic logging
3. **No Duplicate Validation**: Leverages MCP's built-in validation instead of adding extra layers
4. **Testability**: Tools can be unit tested without spinning up HTTP servers or databases
5. **Flexibility**: Drizzle ORM provides database-agnostic storage layer (supports SQLite, PostgreSQL, MySQL, etc.)
6. **Security**:
   - Explicit authorization checks with clean `ctx.access.grant()` API prevent accidental bypass
   - Hardened JWT validation with issuer verification, nbf/exp checks, and clock skew tolerance
   - Instant token revocation via jti blacklist
   - JWKS support for zero-downtime key rotation
   - Stable audience identifiers (`project:<projectId>`) prevent bypass attacks
7. **Maintainability**: Clear boundaries between layers (API → Tools → Storage)
8. **Reusability**: Tools can be called from HTTP API, CLI, tests, or other tools
9. **Type Safety**: Strong TypeScript interfaces (ports) throughout, with adapters implementing them
10. **Clear Naming**:

- `core/` contains cross-cutting concerns (context, factory, access control, define-tool, bindings, JWT)
- `storage/ports.ts` defines contracts  
- `storage/adapters/` implements those contracts for specific databases

11. **Provider Abstraction**: MCP bindings enable polymorphic tool implementations and generic UIs

### Architecture Naming Clarifications

To avoid confusion and maintain clean separation of concerns:

**Tool Definition Pattern:**

- **`defineTool`** (`core/define-tool.ts`): Declarative tool definition function
  - Takes: `name`, `description`, `inputSchema` (JSON Schema), `handler` function
  - Returns: Tool definition with `execute` method
  - Automatically handles: authorization checking, audit logging
  - Handler signature: `async (input: TInput, ctx: MeshContext) => Promise<TOutput>`
  - Validation: Handled by MCP protocol layer (no duplicate validation needed)

Benefits:

- MCP native - uses standard JSON Schema format
- No duplicate validation - leverages protocol layer
- Co-located schema and business logic
- Self-documenting (JSON Schema serves as documentation)
- Easy to test (just call `tool.execute()`)
- Tool definitions can be exposed directly via MCP protocol

**Access Control API:**

- **`ctx.access.grant()`** - Grant access to current tool (from `ctx.toolName`)
- **`ctx.access.grant("TOOL_NAME")`** - Check if user has access to specific tool
- **`ctx.access.grant("TOOL1", "TOOL2")`** - Check if user has access to ANY of the tools (OR logic)
- **`ctx.access.granted()`** - Check if access was granted

The tool name is automatically set by `defineTool` wrapper, so authorization is contextual and clean.

**Context-Related Files:**

- `core/mesh-context.ts` - The core MeshContext interface definition
- `core/context-factory.ts` - Factory function that creates MeshContext instances
- `core/access-control.ts` - Access control helper for authorization tracking
- `api/middlewares/inject-context.ts` - Hono middleware that injects MeshContext into requests

The `core/` folder contains the heart of the application: the context abstraction and its factory. The middleware simply uses the factory to inject context into HTTP requests.

**Storage Pattern: Ports & Adapters**

We follow the Ports & Adapters pattern (Hexagonal Architecture):

- **Ports** (`storage/ports.ts`): Define the contracts/interfaces that the business logic depends on
- **Adapters** (`storage/adapters/`): Implement those contracts for specific databases

This pattern:

- Makes the business logic (tools) database-agnostic
- Allows easy testing with mock adapters
- Enables switching databases without changing tool code
- Follows dependency inversion principle (depend on abstractions, not implementations)

**Why "Adapter" instead of "Implementation"?**

The term "adapter" is more precise and idiomatic in software architecture:

- "Adapter" implies converting one interface to another (database → port interface)
- "Implementation" is too generic and could refer to any code
- "Adapter" clearly signals the Ports & Adapters pattern
- Industry-standard naming that developers recognize

**MCP Bindings: Protocol-Level Interfaces**

Bindings provide an abstraction layer on top of MCP connections:

- **Bindings** (`core/bindings.ts`): Define standard tool contracts (CHAT, EMAIL, STORAGE, etc.)
- **Binding Detection** (`core/binding-detector.ts`): Automatically detect which bindings a connection implements
- **Polymorphism**: Multiple providers (Slack, Discord, Teams) can all implement the same CHAT binding
- **Generic UIs**: Build UI components that work with any provider implementing a specific binding

This enables:

- Swapping providers without code changes (Gmail → Outlook → SendGrid)
- Building reusable UI components that work with any compatible provider
- Filtering marketplace apps by binding type
- Policy statements that grant access to any connection implementing a binding

**JWT Security & Key Management:**

Hardened JWT implementation with enterprise-grade security:

- **Token Validation** (`auth/jwt-issuer.ts`): Comprehensive JWT verification with multiple security checks
  - Issuer validation against configured base URL
  - Clock skew tolerance (60s) for time synchronization
  - Not-before (`nbf`) validation to prevent premature token use
  - Strict expiration (`exp`) enforcement without grace periods
  - Unique JWT ID (`jti`) for revocation tracking
- **Key Rotation** (`auth/jwks-endpoint.ts`): JWKS support for seamless key rotation
  - Multiple active keys identified by `kid` (Key ID)
  - RS256 algorithm with asymmetric keys
  - Public keys exposed via `/.well-known/jwks.json`
  - Zero-downtime key rotation
- **Token Revocation** (`storage/ports.ts`): Instant token revocation via jti blacklist
  - Check against revocation list on every request
  - Automatic cleanup of expired revocations
  - No waiting for token expiry
- **Stable Audience**: Uses immutable `project:<projectId>` format instead of mutable slugs
  - Prevents audience bypass via slug changes
  - Project slug included as separate claim for convenience

Security Benefits:

- Prevents token reuse across systems (issuer validation)
- Handles clock drift gracefully (60s tolerance)
- Enables instant revocation without waiting for expiry
- Supports key rotation without invalidating existing tokens
- Uses stable immutable identifiers for authorization

---

## Technical Architecture

### Runtime & Technology Stack

**Runtime Environment:**

- **Language**: TypeScript on Bun runtime
- **Deployment**: Self-hosted via standalone binary or Docker
- **Supported Platforms**: Linux, macOS, Windows (via WSL2)

**Core Dependencies:**

- **Web Framework**: Hono (lightweight, edge-compatible)
- **Database**: Bun's native SQLite (zero-config default)
- **Database ORM**: Drizzle ORM
- **Authentication**: Better Auth
- **Validation**: Zod
- **JWT Management**: jose library

**Getting Started (Zero Config):**

```bash
# Clone the repository
git clone https://github.com/decocms/admin.git
cd admin/apps/mesh

# Install dependencies
bun install

# Start the server (SQLite database created automatically)
bun run start
```

That's it! The Mesh will automatically:

- Create a local SQLite database at `./data/mesh.db`
- Run all necessary migrations
- Start the server on `http://localhost:3000`
- Expose all management features via MCP protocol at `/mcp`

**Optional Configuration:**

Only one environment variable is supported:

```bash
# Optional: Use PostgreSQL instead of SQLite
DATABASE_URL=postgresql://user:pass@host:5432/dbname
```

All other configuration (OAuth, SAML, etc.) is done via `auth-config.json`:

```bash
# Create optional auth configuration
cat > auth-config.json << 'EOF'
{
  "socialProviders": {
    "google": {
      "clientId": "your-google-client-id",
      "clientSecret": "your-google-client-secret"
    },
    "github": {
      "clientId": "your-github-client-id", 
      "clientSecret": "your-github-client-secret"
    }
  },
  "saml": {
    "enabled": true,
    "providers": [
      {
        "name": "Okta",
        "entryPoint": "https://your-org.okta.com/app/...",
        "issuer": "http://www.okta.com/...",
        "cert": "-----BEGIN CERTIFICATE-----..."
      }
    ]
  }
}
EOF

# Restart to apply auth configuration
bun run start
```

### Database Model

**Core Entities:**

```typescript
// Users & Authentication
interface User {
  id: string;
  email: string;
  name: string;
  createdAt: Date;
  updatedAt: Date;
}

interface Session {
  id: string;
  userId: string;
  expiresAt: Date;
  token: string;
}

// Project Management (Namespace-scoped, like Kubernetes namespaces)
// The database itself represents the workspace/organization boundary
interface Project {
  id: string;
  name: string;
  slug: string; // URL-safe identifier (e.g., "my-project"), unique within workspace
  ownerId: string;
  description?: string;
  createdAt: Date;
  updatedAt: Date;
}

interface ProjectMember {
  id: string;
  projectId: string;
  userId: string;
  roleIds: string[]; // Array of role IDs
  createdAt: Date;
}

// Team Management (within a project)
interface Team {
  id: string;
  projectId: string;
  name: string;
  ownerId: string;
  createdAt: Date;
}

interface TeamMember {
  id: string;
  teamId: string;
  userId: string;
  roleIds: string[]; // Array of role IDs
  createdAt: Date;
}

// MCP Connections (based on MCPConnection model)
type ConnectionType = 'HTTP' | 'SSE' | 'Websocket';

interface MCPConnection {
  id: string;
  projectId: string | null; // Null = workspace-scoped (cluster-level), Set = project-scoped (namespace-level)
  teamId?: string; // Optional: scope to specific team
  createdById: string;
  name: string;
  description?: string;
  icon?: string;
  appName?: string;
  appId?: string;
  
  // Connection configuration (discriminated union)
  connection: 
    | { type: 'HTTP'; url: string; token?: string }
    | { type: 'SSE'; url: string; token?: string; headers?: Record<string, string> }
    | { type: 'Websocket'; url: string; token?: string };
  
  metadata?: Record<string, any>;
  tools?: Array<{
    name: string;
    description?: string;
    inputSchema: object;
    outputSchema?: object;
  }>;
  
  // Detected bindings that this connection implements
  bindings?: string[]; // e.g., ['CHAT', 'EMAIL']
  
  // Scope indicator (derived from projectId, like Kubernetes resource scope)
  scope: 'workspace' | 'project'; // 'workspace' if projectId is null, 'project' otherwise
  
  status: 'active' | 'inactive' | 'error';
  createdAt: Date;
  updatedAt: Date;
}

// Better Auth-based Access Control
// Based on: https://www.better-auth.com/docs/plugins/admin#access-control

// Permission: Resource-based permission (Better Auth format)
// Format: { connectionId: ["tool1", "tool2", "tool3"] }
type Permission = Record<string, string[]>;

// Role: Named set of permissions (Better Auth compatible)
interface Role {
  id: string;
  projectId: string;
  name: string;
  description?: string;
  permissions: Permission; // e.g., { "conn_slack": ["SEND_MESSAGE", "LIST_THREADS"] }
  createdAt: Date;
  updatedAt: Date;
}

// User extends Better Auth User with role field
interface User {
  id: string;
  email: string;
  name: string;
  role: string; // Role name (e.g., "admin", "user", "developer")
  // Better Auth handles other fields (password, sessions, etc.)
}

// API Key (Better Auth API Key Plugin)
// Based on: https://www.better-auth.com/docs/plugins/api-key
interface ApiKey {
  id: string;
  projectId: string;
  userId: string; // The user who created this key
  name: string;
  token: string; // Hashed API key
  permissions: Permission; // e.g., { "conn_slack": ["SEND_MESSAGE"] }
  expiresAt: Date | null;
  createdAt: Date;
  updatedAt: Date;
  // Better Auth handles: enabled, ipAddress restrictions, etc.
}

// Audit Logs
interface AuditLog {
  id: string;
  projectId: string;
  userId?: string;
  accessTokenId?: string;
  connectionId?: string;
  toolName: string; // The tool that was called
  allowed: boolean; // Whether access was granted
  timestamp: Date;
  requestMetadata: object;
  responseStatus?: number;
  denyReason?: string;
}
```

**Database Technology:**

- **Default**: SQLite via Bun's native `bun:sqlite` (zero configuration required)
- **Optional**: PostgreSQL (for larger deployments or multi-instance setups)
- **Migrations**: Automatically applied on startup via Drizzle Kit

**Why SQLite?**

- Zero configuration - works out of the box
- Perfect for self-hosted single-instance deployments
- Native Bun support for excellent performance
- Simple backup and restore (just copy the `.db` file)
- Upgrade to PostgreSQL anytime without code changes

### Authentication System

**Better Auth Integration:**

MCP Mesh uses Better Auth for flexible authentication with multiple providers. All authentication configuration is done via an optional `auth-config.json` file—no environment variables needed!

**Supported Auth Methods:**

1. **Email/Password**: Enabled by default
2. **OAuth Providers**: Google, GitHub, Microsoft, Generic OAuth 2.0
3. **SSO (SAML)**: Enterprise SSO support

**Configuration via `auth-config.json`:**

The file accepts a partial Better Auth configuration object, allowing you to enable only the providers you need:

```json
{
  "emailAndPassword": {
    "enabled": true
  },
  "socialProviders": {
    "google": {
      "clientId": "your-google-client-id",
      "clientSecret": "your-google-client-secret"
    },
    "github": {
      "clientId": "your-github-client-id",
      "clientSecret": "your-github-client-secret"
    },
    "microsoft": {
      "clientId": "your-microsoft-client-id",
      "clientSecret": "your-microsoft-client-secret"
    }
  },
  "saml": {
    "enabled": true,
    "providers": [
      {
        "name": "Okta",
        "entryPoint": "https://your-org.okta.com/app/...",
        "issuer": "http://www.okta.com/...",
        "cert": "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
      }
    ]
  }
}
```

**Implementation:**

```typescript
import { betterAuth } from "better-auth";
import { Database } from "bun:sqlite";
import { drizzle } from "drizzle-orm/bun-sqlite";
import { readFileSync, existsSync } from "fs";
import * as schema from "./storage/schema";

// Load optional auth configuration
let authConfig = { emailAndPassword: { enabled: true } };
if (existsSync("./auth-config.json")) {
  authConfig = JSON.parse(readFileSync("./auth-config.json", "utf-8"));
}

// Initialize database with Drizzle
const sqlite = new Database("./data/mesh.db");
const db = drizzle(sqlite, { schema });

export const auth = betterAuth({
  database: {
    provider: "sqlite",
    db: sqlite, // Better Auth uses the raw SQLite instance
  },
  ...authConfig, // Spread user configuration
});

// Export Drizzle instance for application use
export { db };
```

### Core APIs (MCP Tools)

**MCP-Native API Architecture:**

The Mesh uses a hierarchical namespace structure where all operations are scoped to projects:

**Root-Level APIs** (`/mcp`) - Project Management:

```
POST /mcp/tools/{TOOL_NAME}
Authorization: Bearer <session-token>

// Used for managing projects themselves
```

**Project-Scoped APIs** (`/:project/mcp`) - All other operations:

```
POST /:project/mcp/tools/{TOOL_NAME}
Authorization: Bearer <project-scoped-token>

// Used for connections, policies, teams, etc. within a project
```

**JWT Token Structure:**

Project-scoped tokens include an `aud` (audience) claim:

```typescript
interface MeshTokenPayload {
  // Standard JWT claims (RFC 7519)
  sub: string;           // Subject: Token ID or User ID
  iss: string;           // Issuer: Mesh instance base URL (e.g., "https://mesh.example.com")
  iat: number;           // Issued at: Unix timestamp
  exp: number;           // Expiration: Unix timestamp
  nbf: number;           // Not before: Unix timestamp (prevents premature use)
  aud: string;           // Audience: Stable immutable identifier
                         //   - Workspace token: "workspace" (database-level, projectId is null)
                         //   - Project token: "project:proj_abc123" (namespace-level)
  jti: string;           // JWT ID: Unique identifier for revocation tracking
  
  // Mesh-specific claims (organization is implicit via database connection)
  projectId?: string;       // Project ID (e.g., "proj_abc123") - null for workspace tokens
  projectSlug?: string;     // Project slug (e.g., "my-project") - for convenience, null for workspace tokens
  userId?: string;          // User ID (if user token)
  apiKeyId?: string;        // API Key ID (if API key token)
  role?: string;            // User role (e.g., "admin", "user", "developer")
  permissions?: Permission; // Better Auth permissions: { connectionId: ["tool1", "tool2"] }
}
```

**Built-in Management Tools:**

#### Project Management (Namespace-Scoped, Workspace-Level: `/mcp`)

**PROJECT_CREATE**

```typescript
// Create a new project (namespace) in the workspace
POST /mcp/tools/PROJECT_CREATE
Authorization: Bearer <workspace-token>
{
  "name": "My Project",
  "slug": "my-project", // URL-safe, unique within workspace
  "description": "My awesome project"
}
// Returns: { 
//   id: "proj_abc123", 
//   slug: "my-project", 
//   name: "My Project"
// }
```

**PROJECT_LIST**

```typescript
// List all projects user has access to
POST /mcp/tools/PROJECT_LIST
Authorization: Bearer <session-token>
{}
// Returns: { projects: [...] }
```

**PROJECT_GET**

```typescript
// Get project details
POST /mcp/tools/PROJECT_GET
Authorization: Bearer <session-token>
{
  "slug": "my-project" // or "id": "proj_abc123"
}
// Returns: { id, slug, name, description, ... }
```

**PROJECT_UPDATE**

```typescript
// Update project
POST /mcp/tools/PROJECT_UPDATE
Authorization: Bearer <session-token>
{
  "slug": "my-project",
  "name": "Updated Name",
  "description": "Updated description"
}
```

**PROJECT_DELETE**

```typescript
// Delete project
POST /mcp/tools/PROJECT_DELETE
Authorization: Bearer <session-token>
{
  "slug": "my-project"
}
```

**PROJECT_MEMBER_ADD**

```typescript
// Add member to project
POST /mcp/tools/PROJECT_MEMBER_ADD
Authorization: Bearer <session-token>
{
  "projectSlug": "my-project",
  "userId": "user_abc",
  "roleIds": ["role_789"]
}
```

**PROJECT_MEMBER_REMOVE**

```typescript
// Remove member from project
POST /mcp/tools/PROJECT_MEMBER_REMOVE
Authorization: Bearer <session-token>
{
  "projectSlug": "my-project",
  "userId": "user_abc"
}
```

---

#### Connection Management

Connections can be created at two levels (like Kubernetes resources):

- **Workspace-scoped** (cluster-level): Shared across all projects when `projectId: null` (via `/mcp`)
- **Project-scoped** (namespace-level): Isolated to a single project when `projectId` is set (via `/:project/mcp`)

**CONNECTION_CREATE (Workspace-Scoped / Cluster-Level)**

```typescript
// Create a workspace-wide shared MCP connection (like a Kubernetes cluster-scoped resource)
POST /mcp/tools/CONNECTION_CREATE
Authorization: Bearer <workspace-token>
{
  "name": "Company Slack",
  "description": "Slack integration shared across all projects",
  "icon": "https://...",
  "projectId": null, // null = workspace-scoped (available to all projects)
  "connection": {
    "type": "HTTP",
    "url": "https://mcp.slack.com/mcp",
    "token": "slack-secret-token-XPTO"
  },
  "metadata": {}
}
// Returns: { 
//   id: "conn_abc123", 
//   name: "Company Slack", 
//   scope: "workspace",
//   projectId: null,
//   status: "active" 
// }
```

**CONNECTION_CREATE (Project-Scoped)**

```typescript
// Create a project-specific MCP connection
POST /my-project/mcp/tools/CONNECTION_CREATE
Authorization: Bearer <project-token with aud: "project:proj_abc">
{
  "name": "Project Database",
  "description": "Database connection for this project only",
  "icon": "https://...",
  "projectId": "proj_abc", // Optional: automatically inferred from context
  "connection": {
    "type": "HTTP",
    "url": "https://mcp.postgres.com/mcp",
    "token": "postgres-secret-token-XPTO"
  },
  "metadata": {}
}
// Returns: { 
//   id: "conn_xyz789", 
//   name: "Project Database", 
//   scope: "project",
//   status: "active" 
// }
```

**CONNECTION_LIST**

```typescript
// List all connections available to this project
// Includes both project-scoped AND workspace-scoped (shared) connections
POST /my-project/mcp/tools/CONNECTION_LIST
Authorization: Bearer <project-token>
{
  "scope": "all", // Options: "all" (default), "project", "workspace"
  "teamId": "team_xyz" // Optional filter
}
// Returns: { 
//   connections: [
//     { id: "conn_abc123", name: "Company Slack", scope: "workspace", projectId: null, ... },
//     { id: "conn_xyz789", name: "Project Database", scope: "project", projectId: "proj_abc", ... }
//   ] 
// }
```

```typescript
// List only workspace-scoped connections (cluster-level)
POST /mcp/tools/CONNECTION_LIST
Authorization: Bearer <workspace-token>
{
  "scope": "workspace"
}
// Returns: { connections: [...] } // Only workspace-level shared connections
```

**CONNECTION_GET**

```typescript
// Get connection details
POST /my-project/mcp/tools/CONNECTION_GET
Authorization: Bearer <project-token>
{
  "id": "conn_abc123"
}
// Returns: { id, name, description, connection, tools, status, ... }
```

**CONNECTION_UPDATE**

```typescript
// Update connection
POST /my-project/mcp/tools/CONNECTION_UPDATE
Authorization: Bearer <project-token>
{
  "id": "conn_abc123",
  "name": "Updated Gmail",
  "status": "active"
}
```

**CONNECTION_DELETE**

```typescript
// Delete connection
POST /my-project/mcp/tools/CONNECTION_DELETE
Authorization: Bearer <project-token>
{
  "id": "conn_abc123"
}
```

**CONNECTION_TEST**

```typescript
// Test connection health
POST /my-project/mcp/tools/CONNECTION_TEST
Authorization: Bearer <project-token>
{
  "id": "conn_abc123"
}
// Returns: { healthy: true, latencyMs: 45, availableTools: [...] }
```

**Multi-Level Scoping Benefits (Kubernetes-Inspired Model):**

The Mesh supports two levels of connection scoping, similar to Kubernetes resources:

| Scope | K8s Equivalent | `projectId` Value | Location | Use Case | Example |
|-------|----------------|-------------------|----------|----------|---------|
| **Workspace** | Cluster-scoped | `null` | `/mcp` | Workspace-wide integrations shared across all projects | Slack, email, HR systems, company calendar |
| **Project** | Namespace-scoped | `"proj_abc"` | `/:project/mcp` | Project-specific integrations with sensitive data | Project database, staging environment, project-specific APIs |

**Key Benefits:**

1. **Cost Efficiency**: Connect once to shared services (Slack, Gmail) at workspace-level instead of per-project
2. **Centralized Management**: Update workspace-wide credentials in one place
3. **Flexibility**: Mix and match workspace-level and project-level connections as needed
4. **Security**: Keep sensitive project credentials isolated from other projects
5. **Inheritance**: Projects automatically get access to workspace-level connections plus their own

**Access Pattern:**

```typescript
// When calling CONNECTION_LIST from a project context:
// Returns BOTH workspace-scoped AND project-scoped connections
const connections = await CONNECTION_LIST({ scope: 'all' });

// Result:
// [
//   { id: "conn_1", name: "Company Slack", scope: "workspace", projectId: null, ... },
//   { id: "conn_2", name: "Company Gmail", scope: "workspace", projectId: null, ... },
//   { id: "conn_3", name: "Project DB", scope: "project", projectId: "proj_abc", ... }
// ]
```

**Authorization:**

- Workspace-scoped connections: Require workspace-level permissions (checked at database level)
- Project-scoped connections: Require project-level permissions
- Projects can READ workspace-level connections but cannot DELETE them
- Only workspace admins can manage workspace-level connections

---

#### Policy & Access Control Management (Project-Scoped: `/:project/mcp`)

**POLICY_CREATE**

```typescript
// Create a new policy
POST /my-project/mcp/tools/POLICY_CREATE
Authorization: Bearer <project-token>
{
  "name": "Gmail Send Only",
  "description": "Allow only sending emails",
  "statements": [
    {
      "effect": "allow",
      "resource": "SEND_EMAIL",
      "matchCondition": {
        "resource": "is_connection",
        "connectionId": "conn_abc123"
      }
    },
    {
      "effect": "deny",
      "resource": "DELETE_*"
    }
  ]
}
// Returns: { id: "policy_123", name: "Gmail Send Only" }
```

**POLICY_LIST**

```typescript
// List all policies
POST /my-project/mcp/tools/POLICY_LIST
Authorization: Bearer <project-token>
{}
```

**POLICY_UPDATE**

```typescript
// Update policy statements
POST /my-project/mcp/tools/POLICY_UPDATE
Authorization: Bearer <project-token>
{
  "id": "policy_123",
  "statements": [...]
}
```

**POLICY_DELETE**

```typescript
// Delete policy
POST /my-project/mcp/tools/POLICY_DELETE
Authorization: Bearer <project-token>
{
  "id": "policy_123"
}
```

**ROLE_CREATE**

```typescript
// Create a role (set of policies)
POST /my-project/mcp/tools/ROLE_CREATE
Authorization: Bearer <project-token>
{
  "name": "Email Manager",
  "description": "Can manage email operations",
  "policyIds": ["policy_123", "policy_456"]
}
// Returns: { id: "role_789", name: "Email Manager" }
```

**ROLE_LIST**

```typescript
// List all roles
POST /my-project/mcp/tools/ROLE_LIST
Authorization: Bearer <project-token>
{}
```

**ROLE_UPDATE**

```typescript
// Update role
POST /my-project/mcp/tools/ROLE_UPDATE
Authorization: Bearer <project-token>
{
  "id": "role_789",
  "policyIds": ["policy_123", "policy_456", "policy_789"]
}
```

**ROLE_DELETE**

```typescript
// Delete role
POST /my-project/mcp/tools/ROLE_DELETE
Authorization: Bearer <project-token>
{
  "id": "role_789"
}
```

#### Access Token Management (Project-Scoped: `/:project/mcp`)

**TOKEN_CREATE**

```typescript
// Create access token with policies
POST /my-project/mcp/tools/TOKEN_CREATE
Authorization: Bearer <project-token>
{
  "name": "CI/CD Pipeline Token",
  "policyIds": ["policy_123"],
  "expiresIn": "90d" // or null for no expiration
}
// Returns: { 
//   id: "token_xyz789", 
//   token: "mesh_eyJhbGciOiJIUzI1NiIs...", // Has aud: "my-project"
//   expiresAt: "2025-01-26T00:00:00Z"
// }
```

**TOKEN_LIST**

```typescript
// List all tokens
POST /my-project/mcp/tools/TOKEN_LIST
Authorization: Bearer <project-token>
{
  "includeRevoked": false
}
```

**TOKEN_REVOKE**

```typescript
// Revoke a token
POST /my-project/mcp/tools/TOKEN_REVOKE
Authorization: Bearer <project-token>
{
  "id": "token_xyz789"
}
```

#### Team Management (Project-Scoped: `/:project/mcp`)

**TEAM_CREATE**

```typescript
// Create a new team
POST /my-project/mcp/tools/TEAM_CREATE
Authorization: Bearer <project-token>
{
  "name": "Engineering"
}
```

**TEAM_LIST**

```typescript
// List teams
POST /my-project/mcp/tools/TEAM_LIST
Authorization: Bearer <project-token>
{}
```

**TEAM_MEMBER_ADD**

```typescript
// Add member to team
POST /my-project/mcp/tools/TEAM_MEMBER_ADD
Authorization: Bearer <project-token>
{
  "teamId": "team_xyz",
  "userId": "user_abc",
  "roleIds": ["role_789"]
}
```

**TEAM_MEMBER_REMOVE**

```typescript
// Remove member from team
POST /my-project/mcp/tools/TEAM_MEMBER_REMOVE
Authorization: Bearer <project-token>
{
  "teamId": "team_xyz",
  "userId": "user_abc"
}
```

**TEAM_MEMBER_UPDATE_ROLES**

```typescript
// Update member roles
POST /my-project/mcp/tools/TEAM_MEMBER_UPDATE_ROLES
Authorization: Bearer <project-token>
{
  "teamId": "team_xyz",
  "userId": "user_abc",
  "roleIds": ["role_789", "role_101"]
}
```

#### Audit & Monitoring (Project-Scoped: `/:project/mcp`)

**AUDIT_QUERY**

```typescript
// Query audit logs
POST /my-project/mcp/tools/AUDIT_QUERY
Authorization: Bearer <project-token>
{
  "userId": "user_abc", // Optional filter
  "connectionId": "conn_abc123", // Optional filter
  "toolName": "SEND_EMAIL", // Optional filter
  "startDate": "2025-01-01T00:00:00Z",
  "endDate": "2025-01-31T23:59:59Z",
  "limit": 100,
  "offset": 0
}
// Returns: { logs: [...], total: 1234 }
```

**AUDIT_STATS**

```typescript
// Get usage statistics
POST /my-project/mcp/tools/AUDIT_STATS
Authorization: Bearer <project-token>
{
  "groupBy": "tool", // or "connection", "user", "day"
  "startDate": "2025-01-01T00:00:00Z",
  "endDate": "2025-01-31T23:59:59Z"
}
// Returns: { stats: { SEND_EMAIL: 450, READ_INBOX: 1200, ... } }
```

### The MCP Mesh Proxy API

**Core Concept:**

The MCP Mesh Proxy is the heart of the system. It acts as a secure intermediary that:

1. Accepts requests with project-scoped JWT tokens (with `aud` claim)
2. Validates tokens and checks policies
3. Replaces Mesh tokens with actual service credentials
4. Proxies requests to target MCP services
5. Logs all activity for auditing

**How It Works:**

#### Step 1: Create a Project

```bash
POST /mcp/tools/PROJECT_CREATE
Authorization: Bearer <session-token>
Content-Type: application/json

{
  "name": "My Project",
  "slug": "my-project"
}

# Response:
{
  "id": "proj_abc123",
  "slug": "my-project",
  "name": "My Project"
}
```

#### Step 2: Register an MCP Connection

```bash
POST /my-project/mcp/tools/CONNECTION_CREATE
Authorization: Bearer <project-token with aud: "my-project">
Content-Type: application/json

{
  "name": "Team Gmail",
  "description": "Gmail integration for the team",
  "connection": {
    "type": "HTTP",
    "url": "https://mcp.gmail.com/mcp",
    "token": "gmail-secret-token-XPTO"
  }
}

# Response:
{
  "id": "conn_abc123",
  "name": "Team Gmail",
  "status": "active"
}
```

The Mesh encrypts and stores `gmail-secret-token-XPTO` securely within the project namespace.

#### Step 3: Create Policy and Access Token

```bash
# Create policy
POST /my-project/mcp/tools/POLICY_CREATE
Authorization: Bearer <project-token>
Content-Type: application/json

{
  "name": "Gmail Send Only",
  "statements": [
    {
      "effect": "allow",
      "resource": "SEND_EMAIL",
      "matchCondition": {
        "resource": "is_connection",
        "connectionId": "conn_abc123"
      }
    }
  ]
}

# Response:
{
  "id": "policy_123",
  "name": "Gmail Send Only"
}

# Create access token
POST /my-project/mcp/tools/TOKEN_CREATE
Authorization: Bearer <project-token>
Content-Type: application/json

{
  "name": "Engineering Team Gmail Access",
  "policyIds": ["policy_123"],
  "expiresIn": "90d"
}

# Response:
{
  "id": "token_xyz789",
  "token": "mesh_eyJhbGciOiJIUzI1NiIs...",
  "expiresAt": "2025-01-26T00:00:00Z"
}
```

The `mesh_eyJhbGciOiJIUzI1NiIs...` token contains:

- `aud`: "my-project" (project slug)
- `projectId`: "proj_abc123"
- `tokenId`: "token_xyz789"
- `policyIds`: ["policy_123"]
- Standard claims: `sub`, `iss`, `iat`, `exp`

#### Step 4: Use the Proxy API

```bash
POST /my-project/mcp/:connectionId
Authorization: Bearer mesh_eyJhbGciOiJIUzI1NiIs...
Content-Type: application/json

# Example: Call SEND_EMAIL tool via proxy
POST /my-project/mcp/conn_abc123
{
  "tool": "SEND_EMAIL",
  "arguments": {
    "to": "customer@example.com",
    "subject": "Welcome!",
    "body": "Thanks for signing up"
  }
}
```

**Behind the Scenes:**

1. Mesh validates the JWT token `mesh_eyJhbGciOiJIUzI1NiIs...`
2. Verifies `aud` claim matches project slug from URL path (`my-project`)
3. Extracts `tokenId` and `policyIds` → evaluates policies
4. Checks if `SEND_EMAIL` tool is allowed for `conn_abc123` per policy
5. Retrieves connection config and decrypts the Gmail token: `gmail-secret-token-XPTO`
6. Proxies the request to `https://mcp.gmail.com/mcp`:

   ```bash
   POST https://mcp.gmail.com/mcp
   Authorization: Bearer gmail-secret-token-XPTO
   Content-Type: application/json
   
   {
     "tool": "SEND_EMAIL",
     "arguments": { 
       "to": "customer@example.com",
       "subject": "Welcome!",
       "body": "Thanks for signing up"
     }
   }
   ```

7. Returns the response to the client
8. Logs the request in the audit log (project-scoped)

**Proxy API Specification:**

```typescript
// Proxy endpoint (project-scoped)
POST /:projectSlug/mcp/:connectionId

// Headers
Authorization: Bearer <mesh-issued-jwt with aud: projectSlug>
Content-Type: application/json

// Request Body (standard MCP format)
{
  "tool": string,
  "arguments": object
}

// Response (proxied from actual MCP service)
{
  "result": any,
  "error"?: string
}

// Error Responses
401 Unauthorized       // Invalid or expired token, or aud mismatch
403 Forbidden          // Tool not allowed by policy
404 Not Found          // Connection or project doesn't exist
500 Internal Error     // Proxy or downstream error
```

**Token Structure (JWT Claims):**

```typescript
interface MeshTokenPayload {
  // Standard JWT claims (RFC 7519)
  sub: string;           // Subject: Token ID or User ID
  iss: string;           // Issuer: Mesh instance base URL (e.g., "https://mesh.example.com") - REQUIRED
  iat: number;           // Issued at: Unix timestamp
  exp: number;           // Expiration: Unix timestamp - REQUIRED
  nbf: number;           // Not before: Unix timestamp (prevents premature use) - REQUIRED
  aud: string;           // Audience: Stable immutable identifier - REQUIRED
                         //   - Workspace token: "workspace" (database-level, projectId is null)
                         //   - Project token: "project:proj_abc123" (namespace-level)
  jti: string;           // JWT ID: Unique identifier for revocation tracking - REQUIRED
  
  // Mesh-specific claims (organization is implicit via database connection)
  projectId?: string;       // Project ID (e.g., "proj_abc123") - null for workspace tokens
  projectSlug?: string;     // Project slug (e.g., "my-project") - null for workspace tokens
  userId?: string;          // User ID (if user session token)
  apiKeyId?: string;        // API Key ID (if API key token)
  role?: string;            // User role (e.g., "admin", "user", "developer")
  permissions?: Permission; // Better Auth permissions: { connectionId: ["tool1", "tool2"] }
}
```

**Security Features:**

1. **Credential Isolation**: Original service tokens never leave the Mesh
2. **Encryption at Rest**: All credentials encrypted using AES-256-GCM
3. **Policy Enforcement**: Tools are checked before proxying
4. **Audit Trail**: Every request logged with full context
5. **Token Rotation**: Mesh tokens can be rotated without touching service credentials
6. **Instant Revocation**: Disable a Mesh token immediately without API calls to services

### Self-Hosting Guide

**Prerequisites:**

- Bun runtime (for local deployment), OR
- Docker (for containerized deployment)

That's it! No database setup required.

**Deployment Options:**

**Option 1: Standalone Binary (Recommended for Getting Started)**

```bash
# Download the latest release
curl -L https://github.com/your-org/mcp-mesh/releases/latest/download/mcp-mesh-linux -o mcp-mesh
chmod +x mcp-mesh

# Run with zero configuration
./mcp-mesh start

# The server starts immediately at http://localhost:3000
# SQLite database is automatically created at ./data/mesh.db
```

**Option 2: From Source**

```bash
# Clone and install
git clone https://github.com/your-org/mcp-mesh.git
cd mcp-mesh
bun install

# Run
bun run start
```

**Option 3: Docker (SQLite - Zero Config)**

```yaml
# docker-compose.yml
version: '3.8'

services:
  mesh:
    image: mcp-mesh/server:latest
    ports:
      - "3000:3000"
    volumes:
      - ./data:/app/data           # Persist SQLite database
      - ./auth-config.json:/app/auth-config.json  # Optional auth config
```

```bash
docker-compose up -d
```

**Option 4: Docker with PostgreSQL (Optional - for scale)**

Only needed if you expect high concurrent usage or want to run multiple Mesh instances.

```yaml
# docker-compose.yml
version: '3.8'

services:
  postgres:
    image: postgres:16
    environment:
      POSTGRES_DB: mcp_mesh
      POSTGRES_USER: mesh
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data

  mesh:
    image: mcp-mesh/server:latest
    depends_on:
      - postgres
    environment:
      DATABASE_URL: postgresql://mesh:${DB_PASSWORD}@postgres:5432/mcp_mesh
    ports:
      - "3000:3000"
    volumes:
      - ./auth-config.json:/app/auth-config.json  # Optional auth config

volumes:
  postgres_data:
```

**Environment Variables:**

MCP Mesh is designed with minimal configuration. Only **one** environment variable is supported:

```bash
# Database (optional - defaults to SQLite at ./data/mesh.db)
DATABASE_URL=postgresql://user:pass@host:5432/dbname
```

That's it! All other configuration is done via the optional `auth-config.json` file.

**Authentication Configuration** (`auth-config.json`):

Instead of environment variables, authentication is configured via an optional JSON file:

```json
{
  "emailAndPassword": {
    "enabled": true
  },
  "socialProviders": {
    "google": {
      "clientId": "your-google-client-id",
      "clientSecret": "your-google-client-secret"
    },
    "github": {
      "clientId": "your-github-client-id",
      "clientSecret": "your-github-client-secret"
    }
  },
  "saml": {
    "enabled": true,
    "providers": [
      {
        "name": "Okta",
        "entryPoint": "https://your-org.okta.com/app/...",
        "issuer": "http://www.okta.com/...",
        "cert": "-----BEGIN CERTIFICATE-----..."
      }
    ]
  }
}
```

**Production Considerations:**

1. **SSL/TLS**: Always use HTTPS in production (use a reverse proxy like Caddy or nginx)
2. **Database Backups**:
   - SQLite: Simple file-based backups (`cp data/mesh.db backups/mesh-$(date +%Y%m%d).db`)
   - PostgreSQL: Use `pg_dump` or automated backup solutions
3. **Secret Management**:
   - Secrets (JWT, encryption keys) are auto-generated on first run and stored in the database
   - Protect the `auth-config.json` file as it contains OAuth/SAML secrets
   - Use environment variable substitution in `auth-config.json` if needed for secret management
4. **Monitoring**: Set up health checks and alerting
5. **Rate Limiting**: Implement rate limits on proxy endpoints via reverse proxy
6. **Logging**: Configure structured logging for audit compliance
7. **Scaling**:
   - Single instance: SQLite is perfect
   - Multiple instances: Migrate to PostgreSQL with load balancer
8. **Project Isolation**: Each project operates in its own namespace with isolated credentials

---

## Roadmap

### Phase 1: Core Infrastructure (MVP)

- [x] Database schema design
- [x] Project/namespace architecture
- [ ] Authentication system (Better Auth with JSON config)
- [ ] Project management tools
- [ ] Connection management tools
- [ ] Policy and role management tools
- [ ] Token issuance and validation with `aud` claim
- [ ] Basic proxy implementation (`/:project/mcp/:connectionId`)
- [ ] Audit logging (project-scoped)

### Phase 2: Security & Access Control

- [ ] Fine-grained policy engine with statements
- [ ] Role-based access control
- [ ] Team and member management
- [ ] Credential encryption (AES-256-GCM)
- [ ] Token revocation
- [ ] Rate limiting per project

### Phase 3: Developer Experience

- [ ] CLI tool for project and connection management
- [ ] TypeScript/Python SDKs
- [ ] Web-based admin UI
- [ ] Connection testing tools
- [ ] Interactive documentation
- [ ] Project templates

### Phase 4: Advanced Features

- [ ] Tool composition across connections
- [ ] MCP dependency resolution
- [ ] Response caching layer
- [ ] Webhook support for events
- [ ] Metrics and analytics dashboard (per project)
- [ ] Multi-region deployment support

---

## Contributing

We welcome contributions! Please see our [CONTRIBUTING.md](./CONTRIBUTING.md) for guidelines.

## License

MCP Mesh is open-source software licensed under the [MIT License](./LICENSE).
